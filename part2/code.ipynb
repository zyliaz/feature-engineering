{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d666a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this file, we will add one new column to our predictor data set, Day_of_Week, to see how that impacts the performance\n",
    "# of our ML models for predicting solar output using weather.\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1efcd02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/ndh_pk0s37n95y6svtjfy7hw0000gp/T/ipykernel_20572/3453858087.py:2: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_generation = pd.read_csv('Plant_1_Generation_Data.csv', parse_dates=['DATE_TIME'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DATE_TIME  PLANT_ID_gen   SOURCE_KEY_gen  DC_POWER  AC_POWER  DAILY_YIELD  \\\n",
      "0 2020-05-15       4135001  1BY6WEcLGh8j5v7       0.0       0.0          0.0   \n",
      "1 2020-05-15       4135001  1IF53ai7Xc0U56Y       0.0       0.0          0.0   \n",
      "2 2020-05-15       4135001  3PZuoBAID5Wc2HD       0.0       0.0          0.0   \n",
      "3 2020-05-15       4135001  7JYdWkrLSPkdwr4       0.0       0.0          0.0   \n",
      "4 2020-05-15       4135001  McdE0feGgRqW7Ca       0.0       0.0          0.0   \n",
      "\n",
      "   TOTAL_YIELD  PLANT_ID_weather SOURCE_KEY_weather  AMBIENT_TEMPERATURE  \\\n",
      "0    6259559.0         4135001.0    HmiyD2TTLFNqkNe            25.184316   \n",
      "1    6183645.0         4135001.0    HmiyD2TTLFNqkNe            25.184316   \n",
      "2    6987759.0         4135001.0    HmiyD2TTLFNqkNe            25.184316   \n",
      "3    7602960.0         4135001.0    HmiyD2TTLFNqkNe            25.184316   \n",
      "4    7158964.0         4135001.0    HmiyD2TTLFNqkNe            25.184316   \n",
      "\n",
      "   MODULE_TEMPERATURE  IRRADIATION  \n",
      "0           22.857507          0.0  \n",
      "1           22.857507          0.0  \n",
      "2           22.857507          0.0  \n",
      "3           22.857507          0.0  \n",
      "4           22.857507          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Read the generation data file and parse DATE_TIME as a datetime object\n",
    "df_generation = pd.read_csv('Plant_1_Generation_Data.csv', parse_dates=['DATE_TIME'])\n",
    "\n",
    "# Read the weather data\n",
    "df_weather = pd.read_csv('Plant_1_Weather_Sensor_Data.csv', parse_dates=['DATE_TIME'])\n",
    "\n",
    "# Merge the two dataframes on the DATE_TIME column\n",
    "df_merged = pd.merge(df_generation, df_weather, on='DATE_TIME', how='left', suffixes=('_gen', '_weather'))\n",
    "\n",
    "# Now df_merged contains the combined data\n",
    "print(df_merged.head())\n",
    "\n",
    "# Save the merged dataframe to an Excel file so we can inspect it\n",
    "df_merged.to_excel('Merged_Data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7377a3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-05-15 23:15:00', '2020-05-15 23:30:00',\n",
      "               '2020-05-15 23:45:00', '2020-05-16 00:00:00',\n",
      "               '2020-05-16 00:15:00', '2020-05-16 00:30:00',\n",
      "               '2020-05-16 00:45:00', '2020-05-16 01:00:00',\n",
      "               '2020-05-16 01:15:00', '2020-05-16 01:30:00',\n",
      "               ...\n",
      "               '2020-05-29 04:30:00', '2020-05-29 04:45:00',\n",
      "               '2020-05-29 05:00:00', '2020-05-29 05:15:00',\n",
      "               '2020-05-29 05:30:00', '2020-05-29 05:45:00',\n",
      "               '2020-05-29 06:00:00', '2020-06-03 14:00:00',\n",
      "               '2020-06-17 06:15:00', '2020-06-17 06:30:00'],\n",
      "              dtype='datetime64[ns]', length=110, freq=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/ndh_pk0s37n95y6svtjfy7hw0000gp/T/ipykernel_20572/2050551084.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_specific_panel.sort_values('DATE_TIME', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe for a specific Source Key, which represents one inverter for a group of panels\n",
    "df_specific_panel = df_merged[df_merged['SOURCE_KEY_gen'] == '1BY6WEcLGh8j5v7']\n",
    "\n",
    "# Sort by DATE_TIME\n",
    "df_specific_panel.sort_values('DATE_TIME', inplace=True)\n",
    "\n",
    "# Create a DatetimeIndex with the expected frequency range with a timestamp every 15 minutes ('15T')\n",
    "date_range = pd.date_range(start=df_specific_panel['DATE_TIME'].min(),\n",
    "                           end=df_specific_panel['DATE_TIME'].max(),\n",
    "                           freq='15T')\n",
    "\n",
    "# Find the difference between this ideal range and the actual timestamps in the dataframe\n",
    "missing_timestamps = date_range.difference(df_specific_panel['DATE_TIME'])\n",
    "\n",
    "# show which timestamps are missing in the data for this panel/inverter\n",
    "print(missing_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1c3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with missing timestamps\n",
    "missing_df = pd.DataFrame(missing_timestamps, columns=['DATE_TIME'])\n",
    "\n",
    "# Fill in the blanks on columns we know the value for\n",
    "missing_df['PLANT_ID_gen'] = df_specific_panel['PLANT_ID_gen'].iloc[0]\n",
    "missing_df['SOURCE_KEY_gen'] = '1BY6WEcLGh8j5v7'\n",
    "missing_df['PLANT_ID_weather'] = df_specific_panel['PLANT_ID_weather'].iloc[0]\n",
    "missing_df['SOURCE_KEY_weather'] = df_specific_panel['SOURCE_KEY_weather'].iloc[0]\n",
    "\n",
    "# Concatenate the original dataframe with the dataframe of missing timestamps\n",
    "df_complete = pd.concat([df_specific_panel, missing_df], ignore_index=True)\n",
    "\n",
    "# Sort the complete DataFrame by DATE_TIME\n",
    "df_complete.sort_values('DATE_TIME', inplace=True)\n",
    "\n",
    "# Save the new dataframe to excel so we can look at it\n",
    "df_complete.to_excel('Complete_Data_for_Panel.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eece1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute values for the new rows we created for the missing timestamps\n",
    "# Create a new column 'imputed' and set it to 0 for all rows initially\n",
    "\n",
    "df_complete['imputed'] = 0\n",
    "\n",
    "# Here are the columns I want to impute values for, and I'll use linear interpolation for that\n",
    "columns_to_interpolate = [\n",
    "    'DC_POWER', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD', \n",
    "    'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION'\n",
    "]\n",
    "\n",
    "# Run a loop that adds a value of 1 for all imputed rows so I know which they are later on\n",
    "for column in columns_to_interpolate:\n",
    "    mask = df_complete[column].isna()\n",
    "    df_complete.loc[mask, 'imputed'] = 1\n",
    "\n",
    "    # Interpolate the missing values using linear interpolation\n",
    "    df_complete[column] = df_complete[column].interpolate(method='linear')\n",
    "\n",
    "# Save the new dataframe to excel so we can look at it again\n",
    "df_complete.to_excel('Complete_Data_for_Panel.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7094eb",
   "metadata": {},
   "source": [
    "# 1. Adding Day_of Week (done in-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1cda90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>PLANT_ID_gen</th>\n",
       "      <th>SOURCE_KEY_gen</th>\n",
       "      <th>DC_POWER</th>\n",
       "      <th>AC_POWER</th>\n",
       "      <th>DAILY_YIELD</th>\n",
       "      <th>TOTAL_YIELD</th>\n",
       "      <th>PLANT_ID_weather</th>\n",
       "      <th>SOURCE_KEY_weather</th>\n",
       "      <th>AMBIENT_TEMPERATURE</th>\n",
       "      <th>MODULE_TEMPERATURE</th>\n",
       "      <th>IRRADIATION</th>\n",
       "      <th>imputed</th>\n",
       "      <th>Day_of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>25.184316</td>\n",
       "      <td>22.857507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-15 00:15:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>25.084589</td>\n",
       "      <td>22.761668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15 00:30:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>24.935753</td>\n",
       "      <td>22.592306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15 00:45:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>24.846130</td>\n",
       "      <td>22.360852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-15 01:00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>24.621525</td>\n",
       "      <td>22.165423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>2020-06-17 22:45:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>22.150570</td>\n",
       "      <td>21.480377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>2020-06-17 23:00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>22.129816</td>\n",
       "      <td>21.389024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>2020-06-17 23:15:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>22.008275</td>\n",
       "      <td>20.709211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>2020-06-17 23:30:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>21.969495</td>\n",
       "      <td>20.734963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>2020-06-17 23:45:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>21.909288</td>\n",
       "      <td>20.427972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3264 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE_TIME  PLANT_ID_gen   SOURCE_KEY_gen  DC_POWER  AC_POWER  \\\n",
       "0    2020-05-15 00:00:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "1    2020-05-15 00:15:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "2    2020-05-15 00:30:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3    2020-05-15 00:45:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "4    2020-05-15 01:00:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "...                  ...           ...              ...       ...       ...   \n",
       "3149 2020-06-17 22:45:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3150 2020-06-17 23:00:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3151 2020-06-17 23:15:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3152 2020-06-17 23:30:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3153 2020-06-17 23:45:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "\n",
       "      DAILY_YIELD  TOTAL_YIELD  PLANT_ID_weather SOURCE_KEY_weather  \\\n",
       "0             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "1             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "2             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "4             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "...           ...          ...               ...                ...   \n",
       "3149       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3150       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3151       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3152       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3153       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "\n",
       "      AMBIENT_TEMPERATURE  MODULE_TEMPERATURE  IRRADIATION  imputed  \\\n",
       "0               25.184316           22.857507          0.0        0   \n",
       "1               25.084589           22.761668          0.0        0   \n",
       "2               24.935753           22.592306          0.0        0   \n",
       "3               24.846130           22.360852          0.0        0   \n",
       "4               24.621525           22.165423          0.0        0   \n",
       "...                   ...                 ...          ...      ...   \n",
       "3149            22.150570           21.480377          0.0        0   \n",
       "3150            22.129816           21.389024          0.0        0   \n",
       "3151            22.008275           20.709211          0.0        0   \n",
       "3152            21.969495           20.734963          0.0        0   \n",
       "3153            21.909288           20.427972          0.0        0   \n",
       "\n",
       "      Day_of_Week  \n",
       "0               4  \n",
       "1               4  \n",
       "2               4  \n",
       "3               4  \n",
       "4               4  \n",
       "...           ...  \n",
       "3149            2  \n",
       "3150            2  \n",
       "3151            2  \n",
       "3152            2  \n",
       "3153            2  \n",
       "\n",
       "[3264 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's use time series feature engineering to add a new column called Day_of_Week as a value from 0 to 6\n",
    "df_complete['Day_of_Week'] = df_complete['DATE_TIME'].dt.dayofweek\n",
    "\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4e0165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Baseline MAE: 266.0781670367449\n",
      "Naive Baseline MSE: 183122.3930413372\n",
      "Naive Baseline RMSE: 427.9280232017263\n"
     ]
    }
   ],
   "source": [
    "# The rest of the steps are the same except we now add Day_of_Week into our X feature matrix\n",
    "# Now we will calculate a naive baseline. A naive baseline is a very simple model of our data such as the average or median\n",
    "# The naive baseline gives us something to compare our other models against. If they are any good, we should \n",
    "# easily be able to beat it. We will use the median value as the naive baseline for our solar data.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the feature matrix (X), which now includes our Day_of_Week column, and the target vector (y)\n",
    "X = df_complete[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION','Day_of_Week']]\n",
    "y = df_complete['AC_POWER']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Naive baseline: Use the median AC_POWER from the training set as the prediction\n",
    "y_train_median = y_train.median()\n",
    "y_naive_pred = np.full(shape=y_test.shape, fill_value=y_train_median)\n",
    "\n",
    "# Calculate the MAE for the naive baseline\n",
    "mae_naive = mean_absolute_error(y_test, y_naive_pred)\n",
    "print('Naive Baseline MAE:', mae_naive)\n",
    "\n",
    "# Calculate the MSE for the naive baseline\n",
    "mse_naive = mean_squared_error(y_test, y_naive_pred)\n",
    "print('Naive Baseline MSE:', mse_naive)\n",
    "\n",
    "# Calculate the RMSE for the naive baseline\n",
    "rmse_naive = np.sqrt(mse_naive)\n",
    "print('Naive Baseline RMSE:', rmse_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294cd8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MAE: 34.6605922185422\n",
      "Linear Regression MSE: 10388.706936698569\n",
      "Linear Regression RMSE: 101.92500643462608\n"
     ]
    }
   ],
   "source": [
    "# Now let's try linear regression and see how it performs\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate the MAE, MSE, and RMSE for the Linear Regression model\n",
    "mae_linear = mean_absolute_error(y_test, y_pred)\n",
    "print('Linear Regression MAE:', mae_linear)\n",
    "\n",
    "mse_linear = mean_squared_error(y_test, y_pred)\n",
    "print('Linear Regression MSE:', mse_linear)\n",
    "\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "print('Linear Regression RMSE:', rmse_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19c780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 29.752905015865007\n",
      "Random Forest MSE: 8431.536215790293\n",
      "Random Forest RMSE: 91.82339688657947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the MAE, MSE, and RMSE for the Random Forest model\n",
    "mae_rf = mean_absolute_error(y_test, y_rf_pred)\n",
    "print('Random Forest MAE:', mae_rf)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_rf_pred)\n",
    "print('Random Forest MSE:', mse_rf)\n",
    "\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "print('Random Forest RMSE:', rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc227110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MAE: 97.769593438954\n",
      "SVR MSE: 25649.8732213019\n",
      "SVR RMSE: 160.1557779828811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize the SVR model\n",
    "# Here we are using the default 'rbf' kernel, we can try other configurations later\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_svr_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Calculate the MAE, MSE, and RMSE for the SVR model\n",
    "mae_svr = mean_absolute_error(y_test, y_svr_pred)\n",
    "print('SVR MAE:', mae_svr)\n",
    "\n",
    "mse_svr = mean_squared_error(y_test, y_svr_pred)\n",
    "print('SVR MSE:', mse_svr)\n",
    "\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "print('SVR RMSE:', rmse_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afccc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor MAE: 30.35497475111342\n",
      "Gradient Boosting Regressor MSE: 8623.015445977704\n",
      "Gradient Boosting Regressor RMSE: 92.86019301066364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_gbr_pred = gbr_model.predict(X_test)\n",
    "\n",
    "# Calculate the MAE, MSE, and RMSE for the Gradient Boosting model\n",
    "mae_gbr = mean_absolute_error(y_test, y_gbr_pred)\n",
    "print('Gradient Boosting Regressor MAE:', mae_gbr)\n",
    "\n",
    "mse_gbr = mean_squared_error(y_test, y_gbr_pred)\n",
    "print('Gradient Boosting Regressor MSE:', mse_gbr)\n",
    "\n",
    "rmse_gbr = np.sqrt(mse_gbr)\n",
    "print('Gradient Boosting Regressor RMSE:', rmse_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c323201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor MAE: 34.276523300210705\n",
      "KNN Regressor MSE: 9386.461245185095\n",
      "KNN Regressor RMSE: 96.88375119278307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN regressor, starting with 5 neighbors and can try other configurations later\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_knn_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MAE, MSE, and RMSE for the KNN model\n",
    "mae_knn = mean_absolute_error(y_test, y_knn_pred)\n",
    "print('KNN Regressor MAE:', mae_knn)\n",
    "\n",
    "mse_knn = mean_squared_error(y_test, y_knn_pred)\n",
    "print('KNN Regressor MSE:', mse_knn)\n",
    "\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "print('KNN Regressor RMSE:', rmse_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67f1964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 214074.0000 - val_loss: 192884.6250\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 192205.3438 - val_loss: 151241.8125\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 914us/step - loss: 116744.0703 - val_loss: 60872.0234\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 979us/step - loss: 35111.7109 - val_loss: 20068.2051\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 960us/step - loss: 17449.1445 - val_loss: 17090.3750\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 15532.7568 - val_loss: 15032.3740\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 890us/step - loss: 13992.4609 - val_loss: 13367.7588\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 908us/step - loss: 12745.1719 - val_loss: 11864.1250\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 918us/step - loss: 11710.2285 - val_loss: 10711.7705\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 10944.3701 - val_loss: 9783.0322\n",
      "21/21 [==============================] - 0s 513us/step\n",
      "Neural Network MAE: 62.74037184818832\n",
      "Neural Network MSE: 12257.1451552284\n",
      "Neural Network RMSE: 110.71199192150956\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Standardize the features (also important for NN). I'm commenting this out but left it in to note we would do it\n",
    "# if we hadn't already done it above.\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict on the test set\n",
    "y_nn_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Calculate the MAE, MSE, and RMSE for the neural network model\n",
    "mae_nn = mean_absolute_error(y_test, y_nn_pred)\n",
    "print('Neural Network MAE:', mae_nn)\n",
    "\n",
    "mse_nn = mean_squared_error(y_test, y_nn_pred)\n",
    "print('Neural Network MSE:', mse_nn)\n",
    "\n",
    "rmse_nn = np.sqrt(mse_nn)\n",
    "print('Neural Network RMSE:', rmse_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa31a43f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          MAE            MSE        RMSE\n",
      "Model                                                   \n",
      "Random Forest       29.752905    8431.536216   91.823397\n",
      "Gradient Boosting   30.354975    8623.015446   92.860193\n",
      "KNN                 34.276523    9386.461245   96.883751\n",
      "Linear Regression   34.660592   10388.706937  101.925006\n",
      "Neural Network      62.740372   12257.145155  110.711992\n",
      "SVR                 97.769593   25649.873221  160.155778\n",
      "Naive Baseline     266.078167  183122.393041  427.928023\n"
     ]
    }
   ],
   "source": [
    "# Now let's compare all our models and see how they performed based on these metrics\n",
    "\n",
    "results = {\n",
    "    'Model': ['Naive Baseline', 'Linear Regression', 'Random Forest', 'SVR', 'Gradient Boosting', 'KNN', 'Neural Network'],\n",
    "    'MAE': [mae_naive, mae_linear, mae_rf, mae_svr, mae_gbr, mae_knn, mae_nn],\n",
    "    'MSE': [mse_naive, mse_linear, mse_rf, mse_svr, mse_gbr, mse_knn, mse_nn],\n",
    "    'RMSE': [rmse_naive, rmse_linear, rmse_rf, rmse_svr, rmse_gbr, rmse_knn, rmse_nn]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.set_index('Model', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by the RMSE column in ascending order to view results\n",
    "results_df_sorted_by_rmse = results_df.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "print(results_df_sorted_by_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b143c",
   "metadata": {},
   "source": [
    "# 1) Add Season\n",
    "I added the season as a dummy variable by grouping the datatime data by month, where winter (Dec, Jan, Feb) is 1, spring (Mar, Apr, May) is 2, summer (June, July, Aug) is 3, and fall (Sep, Oct, Nov) is 4. Adding season improved the RMSE of Random Forest and KNN a lot. It is not so much for Gradient Boosting and Linear. And it worsen the Neural Network and SVR. \n",
    "\n",
    "Additionally, I noticed that the data only have May and June data, which could weaken the effect of the season grouping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69e9939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season = df_complete['DATE_TIME'].dt.month%12 // 3 + 1\n",
    "df_complete1 = df_complete\n",
    "df_complete1['Season'] = season\n",
    "df_complete1.to_excel('new_Data_for_Panel.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4581fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 214262.8438 - val_loss: 193338.0156\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 853us/step - loss: 191695.5469 - val_loss: 151211.5469\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 832us/step - loss: 117017.7188 - val_loss: 64410.9453\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 829us/step - loss: 36993.7734 - val_loss: 20765.9609\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 826us/step - loss: 17449.3750 - val_loss: 16150.2012\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 823us/step - loss: 15135.3975 - val_loss: 14203.9922\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 817us/step - loss: 13905.8721 - val_loss: 13069.5322\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 819us/step - loss: 12920.9961 - val_loss: 12054.6279\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 819us/step - loss: 12180.7168 - val_loss: 10898.8213\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 816us/step - loss: 11346.2578 - val_loss: 10093.1338\n",
      "21/21 [==============================] - 0s 436us/step\n",
      "                          MAE            MSE        RMSE\n",
      "Model                                                   \n",
      "KNN                 32.655306    7444.056202   86.278944\n",
      "Random Forest       28.453975    7537.135154   86.816676\n",
      "Gradient Boosting   31.065471    8635.286592   92.926243\n",
      "Linear Regression   35.102106   10379.621479  101.880427\n",
      "Neural Network      63.080012   12758.916332  112.955373\n",
      "SVR                101.637483   27289.308176  165.194758\n",
      "Naive Baseline     266.078167  183122.393041  427.928023\n"
     ]
    }
   ],
   "source": [
    "# Prepare the feature matrix (X), which now includes our Day_of_Week column, and the target vector (y)\n",
    "X = df_complete1[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION','Day_of_Week','Season']]\n",
    "y = df_complete1['AC_POWER']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# naive baseline\n",
    "y_train_median = y_train.median()\n",
    "y_naive_pred = np.full(shape=y_test.shape, fill_value=y_train_median)\n",
    "mae_naive = mean_absolute_error(y_test, y_naive_pred)\n",
    "mse_naive = mean_squared_error(y_test, y_naive_pred)\n",
    "rmse_naive = np.sqrt(mse_naive)\n",
    "# linear regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "mae_linear = mean_absolute_error(y_test, y_pred)\n",
    "mse_linear = mean_squared_error(y_test, y_pred)\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "# random forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_rf_pred)\n",
    "mse_rf = mean_squared_error(y_test, y_rf_pred)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "# SVR model\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_svr_pred = svr_model.predict(X_test)\n",
    "mae_svr = mean_absolute_error(y_test, y_svr_pred)\n",
    "mse_svr = mean_squared_error(y_test, y_svr_pred)\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "# gradient boosting regressor\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbr_model.fit(X_train, y_train)\n",
    "y_gbr_pred = gbr_model.predict(X_test)\n",
    "mae_gbr = mean_absolute_error(y_test, y_gbr_pred)\n",
    "mse_gbr = mean_squared_error(y_test, y_gbr_pred)\n",
    "rmse_gbr = np.sqrt(mse_gbr)\n",
    "# KNeighbors regressor\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_knn_pred = knn_model.predict(X_test_scaled)\n",
    "mae_knn = mean_absolute_error(y_test, y_knn_pred)\n",
    "mse_knn = mean_squared_error(y_test, y_knn_pred)\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "# tensorflow\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "y_nn_pred = model.predict(X_test_scaled).flatten()\n",
    "mae_nn = mean_absolute_error(y_test, y_nn_pred)\n",
    "mse_nn = mean_squared_error(y_test, y_nn_pred)\n",
    "rmse_nn = np.sqrt(mse_nn)\n",
    "\n",
    "# results\n",
    "results1 = {\n",
    "    'Model': ['Naive Baseline', 'Linear Regression', 'Random Forest', 'SVR', 'Gradient Boosting', 'KNN', 'Neural Network'],\n",
    "    'MAE': [mae_naive, mae_linear, mae_rf, mae_svr, mae_gbr, mae_knn, mae_nn],\n",
    "    'MSE': [mse_naive, mse_linear, mse_rf, mse_svr, mse_gbr, mse_knn, mse_nn],\n",
    "    'RMSE': [rmse_naive, rmse_linear, rmse_rf, rmse_svr, rmse_gbr, rmse_knn, rmse_nn]\n",
    "}\n",
    "results1_df = pd.DataFrame(results1)\n",
    "results1_df.set_index('Model', inplace=True)\n",
    "results1_df_sorted_by_rmse = results1_df.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "print(results1_df_sorted_by_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a3ad4",
   "metadata": {},
   "source": [
    "# 1) Group Temperature\n",
    "I added the temperature groups using bins. Grouping temperature improved the RMSE of Random Forest and KNN a lot, but not as good as adding season. The improvement is not so much for Gradient Boosting and Linear, but the Gradient Boosting one is better than the adding season alone. And it also worsens the SVR. \n",
    "\n",
    "I also noticed that changing the bins will alter the results, but I only trial and error for how the bins are set. I might consider clustering using the k-means to see how it might improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9159c420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts per Temperature Category:\n",
      "temp_category\n",
      "low     1664\n",
      "Med1     992\n",
      "high     608\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_complete2 = df_complete1\n",
    "bins = [0, 25, 45, float('inf')]\n",
    "labels = ['low', 'Med1', 'high']\n",
    "df_complete2['temp_category'] = pd.cut(df_complete2['MODULE_TEMPERATURE'], bins=bins, labels=labels)\n",
    "bin_counts = df_complete2['temp_category'].value_counts()\n",
    "print(\"Counts per Temperature Category:\")\n",
    "print(bin_counts)\n",
    "df_complete2 = pd.get_dummies(df_complete2, columns=['temp_category'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c1f2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts per Ambient Temperature Category:\n",
      "A_temp_category\n",
      "low     1750\n",
      "med     1108\n",
      "high     406\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>PLANT_ID_gen</th>\n",
       "      <th>SOURCE_KEY_gen</th>\n",
       "      <th>DC_POWER</th>\n",
       "      <th>AC_POWER</th>\n",
       "      <th>DAILY_YIELD</th>\n",
       "      <th>TOTAL_YIELD</th>\n",
       "      <th>PLANT_ID_weather</th>\n",
       "      <th>SOURCE_KEY_weather</th>\n",
       "      <th>AMBIENT_TEMPERATURE</th>\n",
       "      <th>MODULE_TEMPERATURE</th>\n",
       "      <th>IRRADIATION</th>\n",
       "      <th>imputed</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Season</th>\n",
       "      <th>temp_category_Med1</th>\n",
       "      <th>temp_category_high</th>\n",
       "      <th>A_temp_category_med</th>\n",
       "      <th>A_temp_category_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>25.184316</td>\n",
       "      <td>22.857507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-15 00:15:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>25.084589</td>\n",
       "      <td>22.761668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15 00:30:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>24.935753</td>\n",
       "      <td>22.592306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15 00:45:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>24.846130</td>\n",
       "      <td>22.360852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-15 01:00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6259559.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>24.621525</td>\n",
       "      <td>22.165423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>2020-06-17 22:45:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>22.150570</td>\n",
       "      <td>21.480377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>2020-06-17 23:00:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>22.129816</td>\n",
       "      <td>21.389024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>2020-06-17 23:15:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>22.008275</td>\n",
       "      <td>20.709211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>2020-06-17 23:30:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>21.969495</td>\n",
       "      <td>20.734963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>2020-06-17 23:45:00</td>\n",
       "      <td>4135001</td>\n",
       "      <td>1BY6WEcLGh8j5v7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5521.0</td>\n",
       "      <td>6485319.0</td>\n",
       "      <td>4135001.0</td>\n",
       "      <td>HmiyD2TTLFNqkNe</td>\n",
       "      <td>21.909288</td>\n",
       "      <td>20.427972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3264 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE_TIME  PLANT_ID_gen   SOURCE_KEY_gen  DC_POWER  AC_POWER  \\\n",
       "0    2020-05-15 00:00:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "1    2020-05-15 00:15:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "2    2020-05-15 00:30:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3    2020-05-15 00:45:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "4    2020-05-15 01:00:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "...                  ...           ...              ...       ...       ...   \n",
       "3149 2020-06-17 22:45:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3150 2020-06-17 23:00:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3151 2020-06-17 23:15:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3152 2020-06-17 23:30:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "3153 2020-06-17 23:45:00       4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
       "\n",
       "      DAILY_YIELD  TOTAL_YIELD  PLANT_ID_weather SOURCE_KEY_weather  \\\n",
       "0             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "1             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "2             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "4             0.0    6259559.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "...           ...          ...               ...                ...   \n",
       "3149       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3150       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3151       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3152       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "3153       5521.0    6485319.0         4135001.0    HmiyD2TTLFNqkNe   \n",
       "\n",
       "      AMBIENT_TEMPERATURE  MODULE_TEMPERATURE  IRRADIATION  imputed  \\\n",
       "0               25.184316           22.857507          0.0        0   \n",
       "1               25.084589           22.761668          0.0        0   \n",
       "2               24.935753           22.592306          0.0        0   \n",
       "3               24.846130           22.360852          0.0        0   \n",
       "4               24.621525           22.165423          0.0        0   \n",
       "...                   ...                 ...          ...      ...   \n",
       "3149            22.150570           21.480377          0.0        0   \n",
       "3150            22.129816           21.389024          0.0        0   \n",
       "3151            22.008275           20.709211          0.0        0   \n",
       "3152            21.969495           20.734963          0.0        0   \n",
       "3153            21.909288           20.427972          0.0        0   \n",
       "\n",
       "      Day_of_Week  Season  temp_category_Med1  temp_category_high  \\\n",
       "0               4       2               False               False   \n",
       "1               4       2               False               False   \n",
       "2               4       2               False               False   \n",
       "3               4       2               False               False   \n",
       "4               4       2               False               False   \n",
       "...           ...     ...                 ...                 ...   \n",
       "3149            2       3               False               False   \n",
       "3150            2       3               False               False   \n",
       "3151            2       3               False               False   \n",
       "3152            2       3               False               False   \n",
       "3153            2       3               False               False   \n",
       "\n",
       "      A_temp_category_med  A_temp_category_high  \n",
       "0                    True                 False  \n",
       "1                    True                 False  \n",
       "2                   False                 False  \n",
       "3                   False                 False  \n",
       "4                   False                 False  \n",
       "...                   ...                   ...  \n",
       "3149                False                 False  \n",
       "3150                False                 False  \n",
       "3151                False                 False  \n",
       "3152                False                 False  \n",
       "3153                False                 False  \n",
       "\n",
       "[3264 rows x 19 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete3 = df_complete2\n",
    "bins = [0, 25, 30, float('inf')]\n",
    "labels = ['low', 'med', 'high']\n",
    "df_complete3['A_temp_category'] = pd.cut(df_complete3['AMBIENT_TEMPERATURE'], bins=bins, labels=labels)\n",
    "bin_counts = df_complete2['A_temp_category'].value_counts()\n",
    "print(\"Counts per Ambient Temperature Category:\")\n",
    "print(bin_counts)\n",
    "df_complete3 = pd.get_dummies(df_complete3, columns=['A_temp_category'], drop_first=True)\n",
    "df_complete3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f352e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 213850.3281 - val_loss: 192389.5469\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 855us/step - loss: 190903.3438 - val_loss: 150113.4219\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 837us/step - loss: 114412.7891 - val_loss: 61765.8164\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 828us/step - loss: 34968.3633 - val_loss: 21882.7363\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 884us/step - loss: 18669.5684 - val_loss: 16965.6094\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 905us/step - loss: 16205.0479 - val_loss: 14746.9521\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 885us/step - loss: 14749.3350 - val_loss: 13327.2520\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 831us/step - loss: 13459.3457 - val_loss: 11931.9912\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 833us/step - loss: 12395.8018 - val_loss: 10853.9229\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 822us/step - loss: 11447.6006 - val_loss: 9888.6182\n",
      "21/21 [==============================] - 0s 435us/step\n",
      "                          MAE            MSE        RMSE\n",
      "Model                                                   \n",
      "Random Forest       28.686205    7657.136435   87.505065\n",
      "KNN                 35.795729    8347.307574   91.363601\n",
      "Gradient Boosting   30.680555    8352.942790   91.394435\n",
      "Linear Regression   35.082407   10342.934046  101.700217\n",
      "Neural Network      60.847808   12125.315313  110.115009\n",
      "SVR                112.248116   32623.268516  180.619126\n",
      "Naive Baseline     266.078167  183122.393041  427.928023\n"
     ]
    }
   ],
   "source": [
    "X = df_complete3[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION','Day_of_Week','Season','temp_category_Med1','temp_category_high','A_temp_category_med','A_temp_category_high']]\n",
    "y = df_complete3['AC_POWER']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# naive baseline\n",
    "y_train_median = y_train.median()\n",
    "y_naive_pred = np.full(shape=y_test.shape, fill_value=y_train_median)\n",
    "mae_naive = mean_absolute_error(y_test, y_naive_pred)\n",
    "mse_naive = mean_squared_error(y_test, y_naive_pred)\n",
    "rmse_naive = np.sqrt(mse_naive)\n",
    "# linear regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "mae_linear = mean_absolute_error(y_test, y_pred)\n",
    "mse_linear = mean_squared_error(y_test, y_pred)\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "# random forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_rf_pred)\n",
    "mse_rf = mean_squared_error(y_test, y_rf_pred)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "# SVR model\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_svr_pred = svr_model.predict(X_test)\n",
    "mae_svr = mean_absolute_error(y_test, y_svr_pred)\n",
    "mse_svr = mean_squared_error(y_test, y_svr_pred)\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "# gradient boosting regressor\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbr_model.fit(X_train, y_train)\n",
    "y_gbr_pred = gbr_model.predict(X_test)\n",
    "mae_gbr = mean_absolute_error(y_test, y_gbr_pred)\n",
    "mse_gbr = mean_squared_error(y_test, y_gbr_pred)\n",
    "rmse_gbr = np.sqrt(mse_gbr)\n",
    "# KNeighbors regressor\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_knn_pred = knn_model.predict(X_test_scaled)\n",
    "mae_knn = mean_absolute_error(y_test, y_knn_pred)\n",
    "mse_knn = mean_squared_error(y_test, y_knn_pred)\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "# tensorflow\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "y_nn_pred = model.predict(X_test_scaled).flatten()\n",
    "mae_nn = mean_absolute_error(y_test, y_nn_pred)\n",
    "mse_nn = mean_squared_error(y_test, y_nn_pred)\n",
    "rmse_nn = np.sqrt(mse_nn)\n",
    "\n",
    "# results\n",
    "results2 = {\n",
    "    'Model': ['Naive Baseline', 'Linear Regression', 'Random Forest', 'SVR', 'Gradient Boosting', 'KNN', 'Neural Network'],\n",
    "    'MAE': [mae_naive, mae_linear, mae_rf, mae_svr, mae_gbr, mae_knn, mae_nn],\n",
    "    'MSE': [mse_naive, mse_linear, mse_rf, mse_svr, mse_gbr, mse_knn, mse_nn],\n",
    "    'RMSE': [rmse_naive, rmse_linear, rmse_rf, rmse_svr, rmse_gbr, rmse_knn, rmse_nn]\n",
    "}\n",
    "results2_df = pd.DataFrame(results2)\n",
    "results2_df.set_index('Model', inplace=True)\n",
    "results2_df_sorted_by_rmse = results2_df.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "print(results2_df_sorted_by_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
